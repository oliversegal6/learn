---
title: 机器学习AI
date: 2019-05-24 22:06:47
categories: 
- 软件开发
- 机器学习
---

# 机器学习，深度学习，AI理论

## 机器学习

    人工特征，样本提取

### 基本理论

1. 评价指标
   - 准确，召回，F-score(balance 准确，召回)
   - ROC & AUC（样本不均衡时需要使用）

2. fitting-problem
3. 交叉验证
    不是所有数据都拿来训练模型，需要用一部分数据用来做交叉验证，从而来保证模型在新数据下的稳定性。
4. 模型集成
    把多模型的结果进行整合
5. 正则化
    尽量减少参数，简化模型，而不是更多参数，更复杂的模型。
6. 多分类

### 结果

- 准确，召回，F-score

### 类别，使用场景

梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以), 它是神经网络模型训练最常用的优化算法。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法

1. 有监督学习：
    监督学习是使用已知正确答案的示例来训练网络的。

    - 分类：线性、决策树、SVM、KNN ；集成回归：随机森林、Adaboost、GradientBoosting、Bagging、ExtraTrees。回归与分类的区别在于：回归所预测的目标量的取值是连续的（例如房屋的价格）；而分类所预测的目标变量的取值是离散的（例如判断邮件是否为垃圾邮件）
    - 回归：线性、逻辑回归、决策树、SVM、KNN，朴素贝叶斯；集成分类：随机森林、Adaboost、GradientBoosting、Bagging、ExtraTrees
    - 排序

2. 无监督学习：
    无监督学习适用于你具有数据集但无标签的情况。无监督学习采用输入集，并尝试查找数据中的模式

    - 聚类：k-means,高斯混合模型，
    - 降维：数据维度高，稀疏性高，需要提取特征降维
    - 压缩感知

3. 半监督学习：
    半监督学习在训练阶段结合了大量未标记的数据和少量标签数据。与使用所有标签数据的模型相比，使用训练集的训练模型在训练时可以更为准确，而且训练成本更低

4. 迁移学习：
5. 增强学习：
    强化学习是针对你再次没有标注数据集的情况而言的，但你还是有办法来区分是否越来越接近目标


### 具体算法

#### 线性回归，逻辑回归

Logistic Regression和Linear Regression的原理是相似的，按照我自己的理解，可以简单的描述为这样的过程：

1. 找一个合适的预测函数（Andrew Ng的公开课中称为hypothesis），一般表示为h函数，该函数就是我们需要找的分类函数，它用来预测输入数据的判断结果。这个过程时非常关键的，需要对数据有一定的了解或分析，知道或者猜测预测函数的“大概”形式，比如是线性函数还是非线性函数。

2. 构造一个Cost函数（损失函数），该函数表示预测的输出（h）与训练数据类别（y）之间的偏差，可以是二者之间的差（h-y）或者是其他的形式。综合考虑所有训练数据的“损失”，将Cost求和或者求平均，记为J(θ)函数，表示所有训练数据预测值与实际类别的偏差。

3. 显然，J(θ)函数的值越小表示预测函数越准确（即h函数越准确），所以这一步需要做的是找到J(θ)函数的最小值。找函数的最小值有不同的方法，Logistic Regression实现时有的是梯度下降法（Gradient Descent）。

梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以), 它是神经网络模型训练最常用的优化算法。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法. SGD, BGD, MBGD


## Deep Learning

    自动特征提取

1. CNN卷积神经网络
    convolution, padding,stride, pooling, activation function

    - ResNet
    - AlexNet
    - 纵览

2. RNN

### 常用神经网络：

1. 回归
2. RNN回归
3. 分类
4. CNN分类
5. RNN分类
6. 自编码分类

### 模型步骤：

1. 导入模块并创建数据
2. 建立模型
3. 定义优化器
4. 激活模型
5. 训练模型
6. 检验模型
7. 可视化结果

## 相关工具

### Python

### numpy

NumPy是Python语言的一个扩充程序库。支持高级大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。Numpy内部解除了Python的PIL(全局解释器锁),运算效率极好,是大量机器学习框架的基础库

### Pandas

Pandas是基于Numpy开发出的,专门用于数据分析的开源Python库

### Matplotlab

是Python 2D绘图领域的基础套件，它让使用者将数据图形化，并提供多样化的输出格式

### sklearn

常用的机器学习方法进行了封装，在进行机器学习任务时，只需要简单的调用sklearn里的模块就可以实现大多数机器学习任务。
机器学习任务通常包括分类（Classification）和回归（Regression），常用的分类器包括SVM、KNN、贝叶斯、线性回归、逻辑回归、决策树、随机森林、xgboost、GBDT、boosting、神经网络NN。

常见的降维方法包括TF-IDF、主题模型LDA、主成分分析PCA等等

流程可以理解如下：

    数据加载和预处理
    定义分类器（回归器等等），譬如svc = svm.svc()
    用训练集对模型进行训练，只需调用fit方法，svc.fit(X_train, y_train)
    用训练好的模型进行预测：y_pred=svc.predict(X_test)
    对模型进行性能评估：svc.score(X_test, y_test)


### TensorFlow

TensorFlow可被用于语音识别或图像识别等多项机器学习和深度学习领域, TensorFlow支持CNN、RNN和LSTM算法，这都是目前在Image，Speech和NLP最流行的深度神经网络模型。

### keras

Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：

- 简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）
- 支持CNN和RNN，或二者的结合
- 无缝CPU和GPU切换

### crf++

用于NLP技术领域，其在NLP技术领域中主要用于文本标注，并有多种应用场景，例如：

- 分词（标注字的词位信息，由字构词）
- 词性标注（标注分词的词性，例如：名词，动词，助词）
- 命名实体识别（识别人名，地名，机构名，商品名等具有一定内在规律的实体名词）

### corenlp

coreNLP是斯坦福大学开发的一套关于自然语言处理的工具(toolbox)，使用简单功能强大，有;命名实体识别、词性标注、词语词干化、语句语法树的构造还有指代关系等功
